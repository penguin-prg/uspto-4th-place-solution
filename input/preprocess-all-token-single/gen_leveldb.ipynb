{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PACKAGE_DIR = \"/kaggle/src\"\n",
    "sys.path.append(PACKAGE_DIR)\n",
    "sys.path.append(os.path.join(PACKAGE_DIR, \"Penguin-ML-Library\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 06:12:20.605417: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-15 06:12:20.830977: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-15 06:12:21.494467: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2024-06-15 06:12:21.494583: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2024-06-15 06:12:21.494588: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "from penguinml.utils.logger import get_logger, init_logger\n",
    "from penguinml.utils.set_seed import seed_base\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seed = 46\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/whoosh-wheel-2-7-4/Whoosh-2.7.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.10/site-packages (from Whoosh==2.7.4) (1.5.2)\n",
      "Whoosh is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import bz2\n",
    "import gc\n",
    "import hashlib\n",
    "import json\n",
    "import math\n",
    "import multiprocessing\n",
    "import random\n",
    "import time\n",
    "from glob import glob\n",
    "from typing import List, Set\n",
    "\n",
    "import lz4.frame\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plyvel\n",
    "import polars as pl\n",
    "from penguinml.utils.timer import Timer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import whoosh_utils\n",
    "from const import ALL_KEYS, CPC2TOKENS_PATH, INF, KEY2QUERY, NUM_CPU\n",
    "from solver import SimulatedAnnealing\n",
    "from utils import (\n",
    "    calc_bytes,\n",
    "    compute_ap,\n",
    "    evaluate,\n",
    "    load_list_bz2,\n",
    "    read_bytes_in_range,\n",
    "    save_list_bz2,\n",
    ")\n",
    "\n",
    "\n",
    "def stable_hash(obj, mod: int = 20):\n",
    "    \"\"\"\n",
    "    NOTE: objは`json.dumps`する前のオブジェクト\n",
    "    \"\"\"\n",
    "    obj_str = json.dumps(obj, sort_keys=True)\n",
    "    hash_bytes = hashlib.sha256(obj_str.encode()).digest()\n",
    "    hash_int = int.from_bytes(hash_bytes, byteorder=\"big\")\n",
    "    return hash_int % mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'index.lz4': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -rf db\n",
    "!rm index.lz4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13216540"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = sorted(glob(\"/kaggle/input/preprocess-all-token-single/queries*/*.bz2\"))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 7795572/13216540 [45:31<32:43, 2760.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/preprocess-all-token-single/queries1/US-2002118634-A1.json.bz2 is broken\n",
      "/kaggle/input/preprocess-all-token-single/queries1/US-2002118643-A1.json.bz2 is broken\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13216540/13216540 [1:15:44<00:00, 2908.38it/s] \n"
     ]
    }
   ],
   "source": [
    "# データベースの作成\n",
    "dbs = plyvel.DB(\"db\", create_if_missing=True)\n",
    "txts = open(\"index.lz4\", \"wb\")\n",
    "\n",
    "\n",
    "cursors = 0\n",
    "debug_center2txt = {}\n",
    "debug_count = 0\n",
    "\n",
    "pbar = tqdm(files)\n",
    "for file in pbar:\n",
    "    exist = set()\n",
    "    try:\n",
    "        data = load_list_bz2(file)\n",
    "    except:\n",
    "        print(f\"{file} is broken\")\n",
    "        continue\n",
    "    center = os.path.basename(file).split(\".\")[0]\n",
    "\n",
    "    # dict -> str\n",
    "    txt = json.dumps(data)\n",
    "\n",
    "    start = cursors\n",
    "    compressed_chunk = lz4.frame.compress(txt.encode(\"utf-8\"))\n",
    "    txts.write(compressed_chunk)\n",
    "    txts.flush()\n",
    "    cursors += len(compressed_chunk)\n",
    "    end = cursors\n",
    "\n",
    "    dbs.put(center.encode(), json.dumps((start, end)).encode())\n",
    "\n",
    "    if debug_count % 10000 == 0:\n",
    "        debug_center2txt[center] = txt\n",
    "    debug_count += 1\n",
    "\n",
    "    # if debug_count > 100000:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lz4_in_range(file_path, start_byte, end_byte):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        f.seek(start_byte)\n",
    "        compressed_content = f.read(end_byte - start_byte)\n",
    "        content = lz4.frame.decompress(compressed_content)\n",
    "        return content.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1322/1322 [00:00<00:00, 1679.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['detd:hubach', 2, 22, ['US-3752315-A', 'US-3680697-A']],\n",
       " ['detd:musschoot', 2, 181, ['US-3680697-A', 'US-3087618-A']],\n",
       " ['detd:grizzlies', 2, 213, ['US-4865720-A', 'US-3087618-A']],\n",
       " ['clm:heavies', 2, 250, ['US-2012199519-A1', 'US-6446813-B1']],\n",
       " ['detd:otoole', 2, 272, ['US-2009273-A', 'US-1951705-A']],\n",
       " ['detd:trommels', 2, 292, ['US-2022288640-A1', 'US-4867866-A']]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for center, txt in tqdm(debug_center2txt.items()):\n",
    "    start, end = json.loads(dbs.get(center.encode()))\n",
    "    read_txt = read_lz4_in_range(\"index.lz4\", start, end)\n",
    "    assert txt == read_txt\n",
    "json.loads(read_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs.close()\n",
    "txts.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r db.zip db > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
