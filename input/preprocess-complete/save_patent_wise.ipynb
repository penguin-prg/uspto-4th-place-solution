{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PACKAGE_DIR = \"/kaggle/src\"\n",
    "sys.path.append(PACKAGE_DIR)\n",
    "sys.path.append(os.path.join(PACKAGE_DIR, \"Penguin-ML-Library\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/whoosh-wheel-2-7-4/Whoosh-2.7.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.10/site-packages (from Whoosh==2.7.4) (1.5.2)\n",
      "Whoosh is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m2024-06-22 09:09:43.673889: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-22 09:09:43.762708: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-22 09:09:44.382011: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2024-06-22 09:09:44.382088: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2024-06-22 09:09:44.382093: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "set seed: 46\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import multiprocessing\n",
    "import random\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from typing import List, Set, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plyvel\n",
    "import polars as pl\n",
    "import gc\n",
    "import bz2\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "from multiprocessing import Pool\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import whoosh_utils\n",
    "from const import INF, KEY2QUERY, NUM_CPU, ALL_KEYS\n",
    "from db import CpcToken2RangeDB, SingleTokenDB, TokinezedDB\n",
    "from solver import HitBlock, SimulatedAnnealing, State\n",
    "from utils import compute_ap, evaluate, save_list_bz2, load_list_bz2\n",
    "\n",
    "from penguinml.utils.logger import get_logger, init_logger\n",
    "from penguinml.utils.set_seed import seed_base\n",
    "from penguinml.utils.timer import Timer\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "MODEL_NAME = \"baseline\"\n",
    "CFG = yaml.safe_load(open(os.path.join(PACKAGE_DIR, \"config.yaml\"), \"r\"))\n",
    "\n",
    "init_logger(\"log.log\")\n",
    "logger = get_logger(\"main\")\n",
    "seed_base(CFG[MODEL_NAME][\"execution\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r patent-data\n",
    "!mkdir patent-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251920"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(\"data/*.bz2\")\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 840/840 [16:55:01<00:00, 72.50s/it]   \n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "\n",
    "bs = NUM_CPU * 10\n",
    "\n",
    "\n",
    "def load(file):\n",
    "    try:\n",
    "        data = load_list_bz2(file)\n",
    "    except:\n",
    "        return []\n",
    "    cpc = file.split(\"/\")[-1].split(\".\")[0].replace(\"-\", \"/\")\n",
    "\n",
    "    datas = []\n",
    "    for d in data:\n",
    "        center, token, inner, outer = d\n",
    "        datas.append((center, json.dumps([cpc, token, inner, outer]) + \"\\n\"))\n",
    "    return datas\n",
    "\n",
    "\n",
    "def save(args):\n",
    "    center, text = args\n",
    "    compressed_data = bz2.compress(text.encode(\"utf-8\"))\n",
    "    with open(f\"patent-data/{center}.bz2\", \"ab\") as f:\n",
    "        f.write(compressed_data)\n",
    "\n",
    "\n",
    "for start in tqdm(range(0, len(files), bs)):\n",
    "    end = start + bs\n",
    "    batch_files = files[start:end]\n",
    "\n",
    "    with Pool(NUM_CPU) as p:\n",
    "        ret = p.map(load, batch_files)\n",
    "\n",
    "    buffer = {}\n",
    "    for data in ret:\n",
    "        for center, txt in data:\n",
    "            if center not in buffer:\n",
    "                buffer[center] = \"\"\n",
    "            buffer[center] += txt\n",
    "\n",
    "    with Pool(NUM_CPU) as p:\n",
    "        p.map(save, buffer.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
